{
    "title": "AI A101",
    "description": "Basic programming concepts, variables, and control structures",
    "questions": [
        "What are the main objectives of the AI 101 training session, and how do they relate to research practices?",
        "How did the release of ChatGPT in November 2022 change public awareness and use of generative AI?",
        "What is the difference between artificial intelligence (AI), generative AI, and large language models (LLMs)?",
        "How do tokens function in large language models, and why are they important for prompting and outputs?",
        "What is the “CLEAR” framework for effective prompting, and how does it improve AI outputs?",
        "Why might the same prompt produce different results across tools like ChatGPT, Gemini, or Copilot?",
        "What role does retrieval augmented generation (RAG) play in specialized research tools, and how does it increase trustworthiness of outputs?",
        "How do reasoning models differ from standard LLMs, and what advantage do they provide for complex problem-solving?",
        "What are some of the ethical and practical concerns mentioned in the training regarding generative AI use in research?",
        "How do customizable settings (like profile traits in ChatGPT or Claude) influence the quality and relevance of AI-generated responses?"
    ],
    "knowledgetext": "so welcome everybody we are going to get started with our session today um my name is me lay and I'm a Health Sciences librarian here at the njm Health Sciences Library on the bantin campus so I am going to be leading the first of three sessions that the library is doing on uh an introduction to kind of AI from different perspectives and considering different things so note that the slides for today are available um using the QR code in the upper right hand corner there as well as the link on the slide there and I believe Justin has already popped it into the chat as well so in the session today there will be a lot of me kind of showing you things um so it's always great if you want to follow along to kind of see it in action so having the slides will enable you to follow along with the links so before we begin I do want to acknowledge um where I am today and where I live and where I work so this is the UFM territory acknowledgement and I know that many of us have seen or read it before but I think it's important each time to reread it and reabsorb kind of what it is trying to convey um to us so it is the University of Manitoba campuses are located on the original lands of the mishab the NWA the Anin the Dakota oate and the den and on the national homeland of the Red River mate we respect the treaties that were made on these territories we acknowledge the harms and mistakes of the past and we dedicate to move ourselves forward in partnership with indigenous communities in a spirit of reconciliation and collaboration so personally um as a child of immigrants and of a refugee I do recognize the importance of um acknowledging the lands and the history of the people um that we come from and who are here before us and so this statement it always kind of reminds me of that kind of of that importance of the long history of this land and the people who have taken care of it and the ongoing process of reconciliation so to move kind of back to our session today so the objectives you probably all saw them when you registered but they are to describe how different AI tools work and can be applied to your research process to Aid you in constructing effective prompts to use the systems hopefully a little bit more efficiently and then to evaluate some of the different tools and their outputs so a lot of time will be spent kind of hopefully looking through the tools but we do need to understand kind of how the how the systems work as well in order to use everything kind of efficiently and effectively so the outline for the session is first I'm going to dive into a little bit of a background in terms of an introduction to generative AI spend some time on prompting and then more more time even uh looking at these tools and at the very end we will do our kind of AI sluth so I don't know for people who when you registered if you saw it that um because it's a three-part session at the end of each session we kind of have a little mystery for you to solve using AI tools and if you solve kind of all three parts they kind of lead from one to the next we do have a contest um so you have the chance to win some some Ai and Library related projects or um prizes so uh definitely stay to the end of the session for that and my colleague Justin uh F who is in the chat he is happy to answer any and all um questions that you might have so please send your questions if something isn't clear if you want me to go back over something I'm always happy to explore something more in depth and um also if you have technical issues you can reach out to Justin and he will be doing our next session as well okay but before we dive in I really wanted to get a sense because we are a slightly larger group and I know people come with different experiences so I wanted to get a sense of attendees and participants familiarity with AI in general so there is a mometer here you can use the QR code or you can go to ment.com and enter in the code there and then we will take a look okay so I believe you should still be able to see um the mentee code and I'll just wait a second for people to come in and then we will start with the the first question so the first question is I have deliberately used a generative AI tool in the past month and I'm very intentional about the use of the word deliberate and it's because so many of these things we might not be aware of that they're already kind of embedded and integrated into systems so you might not even uh kind of be aware that you're using some of them um okay but so overwhelmingly people are using these tools um probably different from when I first started teaching a variation of this session when uh a lot more of it was kind of in the no the no range okay so could you define the following uh large language models natural natural language processing or retrieval augmented uh generation rag so none of them have to be perfect definitions but could you muddle your way through describing what these things are um if asked okay so a little bit more about large language models okay and we will yeah we're going to talk about all of these as well great okay so then I wanted to see how comfortable are people with the concept and the Practical applications of generative AI so I know that it can make some people very uncomfortable probably not uncomfortable they kind of haven't used it at all don't really understand other than that it's out there and it exists so okay a lot of people kind of in the middle so we hear about it a lot um you're probably using it a bit um but maybe not considering yourself very experienced as of yet okay great okay this one is I'm always interested is which one have you used the most so maybe that's chat jpt but I'm also always interested in what other people are using uh in their work or in their personal kind of searching and use okay so co-pilot yes which I think more of us are using because of its integration with the Microsoft environment that we have here at the U ofm some deep seeks okay oh reflexivity um okay Gemini okay this is kind of okay there we go oh perplexity yep okay deep seek Gemini yeah okay so most of the big ones are represented uh okay oh and notebook oh yeah we don't talk about notebook today but I'm a big fan of it great okay so then hopefully what are you hoping to learn or gain from this session obviously you can't kind of hit everything but just wanted to get a rough idea of what people were hoping to take away from this session today just an introduction okay that's great improving prompts yeah be more comfortable okay in ethical ways so I will say for the person who said ethical is we're really going to dive deeper into that in our third session um I don't really talk too much about um ethics environment biases privacy any of that in the session today but we will definitely talk about it in the third session if you haven't registered um for it yet okay great and then um this slide I'm just going to leave it it's going to exist so if you don't feel comfortable kind of asking questions through the chat or something occurs to you you can always put it there and we will get back to it at the end of the session today okay so kind of as shown in the Mente I and kind of our own my own kind of knowledge I do recognize that everyone kind of comes to this session or kind of to these kinds of sessions with different levels of experience so some of what I'm going to talk about today or even in the next little section is going to be a refresher and some of it might be brand new but I really believe that in order to understand how to use these tools more effectively you really kind of have to have a basic understanding of their underlying structure and what people kind of mean when they're talking about um these tools and large language models and that kind of thing and and I do also want to share my general kind of caveat here about AI is that I am not an expert I'm not a computer scientist and AI is a massive field that um has people with very different uh different levels of experience and and expertise and really I'm someone who has an interest and have done my best to kind of keep up and read and think about its implications for higher education for teaching for research but I'd be cautious of anyone who says that they kind of are a true expert in Ai and it it changes so fast and so you really have to kind of keep on it to stay up to dat with what's happening so even though I have been working to kind of update these and create new slides things change all the time um so those are my my caveats okay so let's go over a very very abbreviated timeline so you can kind of understand why we are where we are kind of today in you know March 202 2025 so in terms of the development of AI it was really be it really began in kind of the 50s and between the 1950s and let's say 2020 which is a lot of history kind of packed in there that is when the really kind of initial AI development begins when the kind of the key meetings were held and depending on you know Government funding there were es and flows and how much work was being done but that was those were those kind of really early stages when AI certainly existed but a lot of people weren't really thinking about it it wasn't part of their everyday uh their everyday life I would say for most people and then in November 22 2022 is when the company open AI released chat GPT to the public and that was really just kind of the explosion of um generative Ai and knowledge of AI kind of in the general population and it really allowed for that kind of What's called the natural language searching where you can put in a question like you would ask a friend a question and you would get that kind of response back so it really changed how people interacted with these systems and then throughout all of 2023 is when different gener uh generative AI tools really began to flood the market so some of them were built kind of um using open AI technology some of them were their own companies as people just everyone was racing to um develop and and launch their own products and really they became quite easily accessible and at the same time we started having discussions maybe not as much as we should have but on kind of the ethics the safety copyright implications misinformation all of that that is associated with generative AI so those were all going on I would say in 2023 and continue to go on today on to today so then in 2024 is when we began to see even more rapid kind of release of new models and what happened is so you have say um chat GPT but you also have all the other models as well that we will talk about and what happened is that they started to change from being just purely text based to being kind of multimodal so before you could put in a text question and you'd get a text response and in 2024 we began to see more well I could put in um I could input a video and I could get a video output could put in a picture or ask for put in a text and get a picture out so how the information was put in and what was kind of uh produced as an output began to change and what also began to change in 2024 was what are called um not what call but basically how many tokens could be kind of recognized by these models and so tokens are essentially how much content roughly aligned with how many words you can put into a prompt and how much can come out and so when these kind of models first came out it was like okay um you know a couple thousand so you know you could ask it long questions and you could get you know pretty long responses back but what began to happen in 2024 is how much information you could put in to ask a question or a prompt and how much could come out really really changed and you're now up to kind of millions of prompts and what that means is that these longer inputs can really increase the scope and complexity of problems that can be solved so you could say put in an entire book or an entire um like all the reports ever on say climate change and uh begin to kind of analyze data and ask questions about its contents and then in 2025 and kind of Beyond is so in late 2024 early 2025 is when we began to see the um release of much more advanced kind of reasoning model models and so that is ongoing and I would say a lot more discussion about how close we are to what is called um artificial general intelligence as opposed to narrow which is where we currently are and that is that kind of AI that I think a lot of people think of where basically it's replacing uh you know our jobs those kinds of things so much more talk about when that actually is going to arrive with people kind of giving Hard dates so that is where we are for kind of early 2025 okay and then how do we think about where generative AI Falls within kind of the broad umbrella term of AI and AI really is it is an umbrella term and probably what's going to happen even in this own session is that I'm going to say AI when really I mean generative Ai and it's really just these things that are so kind of intertwined that sometimes it's hard to separate them into neat categories so mostly in the session today when I'm talking about AI relation to research and teaching and learning it it relates back to generative AI which you can see here is this um the circle kind of down at the bottom and they are tools that allow for the generation of new content they are generating new content um such as text and videos and images but um sometimes people are often talking about these other types of AI um and so just to be aware that there are very much different categories and purposes and for them okay so let's just briefly talk about large language models so llms so these are some of the companies that have um kind of created or have released some of the the most well-known large language models but what happens is that these llms are trained on kind of massive amounts of text and media um scraping the internet just huge huge amounts of data and then from that they're kind of trained on that and then as a result of the information that they are then able to start generating new content in the form of text or kind of say other media and then what they kind of do is they make predictions based on what they have seen in that huge amount of training data they're able to make predictions on kind of what words or phrases are most likely to come next in a sentence so um essentially what they do is they use kind of um natural languaging process natural language processing techniques to kind of understand and represent our language which is text based and turn it into a format that can be understand uh understood by computers so uh kind of to code right and these large language models are the kind of the backbone or the engines that run um things like chat GPT and other tools and there are a lot out there so there is a lot kind of um keep track of you can see um this is uh let me just see if it's going to load properly this is the chatbot Arena where basically people can Rank and see all of the different models that are out there to see how they're doing and sometimes I find it really slow to load but if you have the slides you can um you can do it but basically what people do is they compare the different models no nothing's going to work for me um on this one I'll leave it in the background and come back to it um but just be aware those are some of the different there's a lot out there different versions different models um and they all have kind of strengths and weaknesses some of which we're going to talk about today okay oh so so I mentioned that what they do is kind of make predictions so I think to dig into the kind of the idea of text predict text uh prediction is a really helpful way to think about how these models work and this example was shared with me by um a colleague and I I found it really useful in how I thought about the tool but think about what these kind of systems are doing is text prediction on this enormous massive scale and then predicting the probability of what word is likely to come next so you can see in my kind of sample here is I read a good blank last week so the highest probability is that the word is going to be book but it also kind of weighs the probability that it could be these other um these other words essentially but it's making a prediction based on what it has kind of processed in its training data to then give you that next word in the sentence so you can then extrapolate on how the systems kind of take this small little sample and then apply it to entire sentences paragraphs full kind of full fledge reports that kind of thing it's really um making making predictions and um one one thing I read is just think of it kind of as a really fancy word calculator at this point most of them they're not really thinking for themselves you kind of punching in a calculator you're punching in two plus three and it returns five but does the calculator understand what five means right like not really and the same or not not not really it doesn't the same thing applies with these large language models they don't know kind of what you're saying it's a very um sophisticated parrot that can return uh sequences of words and sentences back to you um that makes sense and um there there's obviously a lot more nuance and complexity here but I think that I'm kind of glossing over but I think it hopefully shows you why you won't often get the same answer twice right why why when you ask the same question multiple times you're going to get different answers is it's making it's running all of these models it's making different predictions um it's all about kind of probab here okay so I know that this is kind of it's pretty small to see but um these are kind of what the system is interpreting for you so when we we talk about like words but what we're really talking about is these systems are um they're making predictions but not on words but instead on tokens so if you ever hear people talk about tokens what that means if you look here you can see I've put in a sentence I put in pardon me a few sentences and it shows you how it has taken these words translated it to tokens some of which align kind of oneto one with a word like here is a word here is one token but depending on how you you use punctuation um how you use if you make spelling errors those kinds of things it will eat up more and more tokens um and so that is what happens um is they kind of take these token and they translate it into code and then kind of put your um your output back um this is what's happening all kind of behind the scenes with these different models that you're using okay so these large language models don't worry about having to see um all the detail of this timeline but as I've kind of talked about these large language large language models are kind of the the architecture on which all of these generative AI tools that we're going to talk about are built and they change really fast so the point of this timeline is really just to show you how quickly things um develop so you can see it goes to kind of early early 2020s where you know gpt3 is kind of the big thing to um even as of like 2 months ago you know three different uh new versions had kind of been released so they change really really fast and they build on each other in different ways depending on the company so that's one thing to really be aware of when you're using the different systems is that even though they're kind of a chat GPT or they're called something else like Gemini you may not always know what version you're using and it's really helpful to kind of be able to dig into that to understand how the different systems are working okay so with generative AI in general but large language models more specifically in terms of how to use them there are a few different strategies that people tend to take and so one is this kind of zero shot prompt where you give it a prompt and um with no examples provided and it just returns kind of the answer that it thinks you're asking for the second kind of one shot is where you give an example and then you ask it to do it again for you um so it has that context the third is the few shot prompting where you're providing multiple examples and then it will kind of return an answer and then there's this idea of kind of chain of thought prompting which is essentially a way that allows the large language model to kind of walk itself through different steps um and then return the final answer to you so we'll talk a little bit more about prompting in the next section but just be aware that those are the different kinds of techniques that are out there in terms of how to um how to work with them okay so in terms of prompting if you haven't heard the term before I think most people probably have by now it's it's basically asking the system a question or a command or putting in some information to get that output back so a prompt can really be anything but the the thing that I always emphasize when we talk about prompting is that really it's a conversation like that's the really fundamental way to think about it is that it's a conversation it's a back and forth between you and the system so even though it's not a human you can think about it as a conversation where you start by kind of setting it up so you set up the context for what you want you give it some instructions it gives you some output and then you give it some feedback right you ask it to elaborate you ask it to change things you give it um some additional context and then you get that output back and the reason why I think that's important is because if you kind of put in a prompt and then you don't get what you want a lot of people just kind of give up but if you think about it as a conversation um you will be able to get more out of it because you're going back and forth like you would with um with a friend or with a colleague if you weren't clear um so that's the way I always encourage people to think about it and so in terms of prompting uh I I think that the CLEAR framework is a really helpful way of thinking about how to make better prompts so it's uh basically the first one is context so kind of giving the system background knowledge on what you want so if you're asking for a resume ask it for a resume for a specific role with specific skills those kinds of things the second is Length um so how long do you want it do you want it really brief do you want a sentence do you want a paragraph is it supposed to be you know a 30-minute talk those kinds of things um examples so if you have examples of what you want that's really helpful too to provide to it and then what is the audience so um who's going to be reading this right are you writing it for uh senior executives are you writing it for grade seven students those kinds of things and then format is really helpful too so what format do you want it in is it an email do you want it in a table um do you want it in an infographic um giving those kinds of cues are really really helpful in terms of providing better prompting uh tips and then the other kind of tips that I always encourage people to think about is um giving role playing so giving the AI kind of a role so if you are like you are an expert in this subject area you are my um a fitness coach give it a role so that it is able to kind of adopt that Persona and give you um content that matches what you want also in terms of clarifying and refining always really helpful to kind of use your judgment but ask it to do things again in a slightly different way um specifying tone you can get really creative with tone sometimes it's helpful sometimes it's not so helpful but you can always specify that um and then finally and this is one that I use a lot is to actually get it to ask you questions so um if you want it to create something like a lesson plan um often I won't provide it with a lot of detail I'll just say you know I'm a grade 10 history teacher and I'm teaching on the Second World War please ask me five questions so that you can create a good lesson plan for me and then it will return the questions I'll fill them in and then it will do the work so making it a little bit more interactive that way um can often really help improve the quality of what you're getting back okay so these are the tools that we're going to talk about in just a moment but just to be aware that really uh what has been released to date is a lot more than just kind of chat GPT but chat GPT is the one that really um has captured kind of our imagination and most people are using okay so I do want to just pause here and see if there are any kind of quick questions or reflections that people want to share um so feel free to just put them into the chat if there's anything you want to ask okay great okay so then let's talk about a few of these um tools so these are some of the more popular ones but by no means is this all of them but um just to talk about a couple of the the key features of them and one thing I will note is that the tools really change often so sometimes I make these slides and then they are immediately out of date by the time I go to teach them but the thing with um chat GPT which is um open AI's version is it's very much kind of free flowing it's very easy to use it has a very um user friendly interface and it really is kind of the leader in generative AI tools there is the pro version of it as well so um you can pay I think it's $20 a month to get the pro version which allows you more access to kind of the updated tools the thing to be aware of is that even in the free version they do rotate in some of the the newer versions so just be aware if you can't pay for the pro version you are still going to have access to um some of the newer versions that are released it's just not going to be consistent um so that's one thing about chat GPT Google Gemini is the rebranding of what was previously known as B so if you heard of B before it's essentially the same thing but it's the rebranding of it Gemini and the the thing that's interesting about Gemini is because it's a Google product it is connected to Google workspace so if you are using a lot of Google um the Google tools that's really helpful because it's fully integrated um so that might be one of the reasons why you might want to use that one um perplexity is another popular one and I really like perplexity and um one of the reasons why I like it is that it actually provides you with citations so unlike chat GPT which doesn't provide you with citations it does provide you with links back to where it got the information and it also I think is really nice in that it provides you with options so it doesn't just give you one answer it often will give you several kind of versions or ways of thinking about it so it's one that I recommend to people um co-pilot we mentioned already this is the one that's integrated with Microsoft and so if you're working in kind of the Microsoft environment then um it's going to be really useful for you because it's built right into um teams it's built right into outlook it's built right into um word and Excel those kinds of things so you're going to have easy access to it um claude is um a another one that I think is really interesting in that it really puts an emphasis on safety um it's probably one of the ones that is considered to be um the most focused on safety and um is quite popular because of that um and then I will just mention pi because I think it's an interesting one in that pi is marketed as being much more personal so rather than kind of thinking about it as like um a work tool pi is really thought of as kind of like a personal companion so it's marketed as kind of your friend your um your coach that kind of thing um so that might be one that people are interested in so those are some of the tools that are out there okay so then I did want to mention some of the other specialized tools that are out there so for example um elicit um scite ai research rabbit scolar c these are some of the ones that are more specific to um our world as researchers or as um academics and the reason why these ones are interesting is because they have a slightly different model of how they're put together so when we talked about the large language models I mentioned that they're trained on you know massive amounts of internet data and media data the thing with these specialized ones is that they often use what is called rag so retrieval augmented generation and so what that means is that they are um taking kind of the generative AI component but they're combining it with searching specific databases so they're kind of the combination of that natural language searching but connecting it with databases and so for example um if you use say research rabbit or site.ai it is drawing from say pubmed and specific article databases and then returning that back to you which is very different from chat GPT where you don't know what data it's been trained on right so that's why it's sometimes considered to be much more trustworthy um is that it's kind of pulling from specific um specific sets of data so those are some of the more specialized ones that you might want to take a look at depending on what kind of research you're doing okay so I'm going to skip this because I think I'm going to run out of time okay so I know that we kind of went through a lot in a very short period of time so I wanted to come back to our objectives for the session so um the first one was describe how different AI tools work and can be applied to your research process so I know that we didn't get into a lot of detail but I hope that you at least have a sense of the different kinds of um AI tools that are out there and what some of the differences are between them and why you might want to use some of them um constructing effective prompts so we talked about the CLEAR framework we talked about different strategies like zero shot few shot those kinds of things so hopefully you have a sense of some of the different strategies you can use and then evaluating some of the different tools and their outputs so we talked a little bit about that I know we didn't get a lot into that but hopefully you have a sense that not all tools are built the same and that it's worth trying out different ones to see um what works for you so we are now at the end and so as I mentioned we are doing a little bit of a contest and so what this is is a chance for you to use your knowledge that you have gained today to solve a mystery so I don't want to say too much because I don't want to give it away um but essentially this is what we're going to do is we're going to put you into breakout rooms so that you can work on it together so you won't be doing it alone you'll be doing it in small groups and you will be using um a set of AI tools that we will give you to help solve the mystery so if you are able to solve it you'll move on to the next one and then the next one and then if you solve all three you will be entered to win some prizes so um that's what we're going to do so I'm going to stop sharing and then put you into your breakout rooms"
}
